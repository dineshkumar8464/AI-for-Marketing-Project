{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/chat-bison-001\n",
      "models/text-bison-001\n",
      "models/embedding-gecko-001\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-pro-vision\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-1.5-pro-001\n",
      "models/gemini-1.5-pro-002\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-flash-001\n",
      "models/gemini-1.5-flash-001-tuning\n",
      "models/gemini-1.5-flash\n",
      "models/gemini-1.5-flash-002\n",
      "models/gemini-1.5-flash-8b\n",
      "models/gemini-1.5-flash-8b-001\n",
      "models/gemini-1.5-flash-8b-latest\n",
      "models/gemini-1.5-flash-8b-exp-0827\n",
      "models/gemini-1.5-flash-8b-exp-0924\n",
      "models/gemini-2.0-flash-exp\n",
      "models/gemini-2.0-flash\n",
      "models/gemini-2.0-flash-001\n",
      "models/gemini-2.0-flash-lite-001\n",
      "models/gemini-2.0-flash-lite\n",
      "models/gemini-2.0-flash-lite-preview-02-05\n",
      "models/gemini-2.0-flash-lite-preview\n",
      "models/gemini-2.0-pro-exp\n",
      "models/gemini-2.0-pro-exp-02-05\n",
      "models/gemini-exp-1206\n",
      "models/gemini-2.0-flash-thinking-exp-01-21\n",
      "models/gemini-2.0-flash-thinking-exp\n",
      "models/gemini-2.0-flash-thinking-exp-1219\n",
      "models/learnlm-1.5-pro-experimental\n",
      "models/embedding-001\n",
      "models/text-embedding-004\n",
      "models/gemini-embedding-exp-03-07\n",
      "models/gemini-embedding-exp\n",
      "models/aqa\n",
      "models/imagen-3.0-generate-002\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyA2WApH-qFk1hetH3wmpT1pR6J0OOm3U3c\"\n",
    "\n",
    "# List all available models\n",
    "models = genai.list_models()\n",
    "\n",
    "for model in models:\n",
    "    print(model.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"**Short & Catchy:**\\n\\n* AI-Powered Ads: Smarter Targeting, Bigger Impact.\\n* Ads that Learn. Results that Grow.\\n* The Future of Advertising is Here.\\n* Unlock Your Audience with AI.\\n* AI: Amplifying Your Advertising.\\n\\n**Benefit-Focused:**\\n\\n* Maximize ROI with AI-Driven Advertising.\\n* Reach the Right Customer, Every Time.\\n* Stop Guessing, Start Knowing: AI Advertising.\\n* Data-Driven Ads for Unprecedented Results.\\n* Personalized Advertising, Powered by AI.\\n\\n**Creative & Intriguing:**\\n\\n* Advertising that Thinks.\\n* The Intelligent Way to Advertise.\\n* Evolve Your Advertising with AI.\\n* Let Your Ads Work Smarter, Not Harder.\\n* Experience the Power of Predictive Advertising.\\n\\n\\n**Specific to a Platform/Service:**\\n\\n* [Platform Name]: AI Advertising Made Easy.\\n* The Only AI Advertising Platform You'll Ever Need.\\n* Get More from Your Ad Spend with [Platform Name].\\n\\n\\nWhen choosing, consider your target audience and the specific benefits of your AI advertising solution.\" additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []} id='run-25294946-a70f-4a09-86d3-b6a6639e218f-0' usage_metadata={'input_tokens': 10, 'output_tokens': 229, 'total_tokens': 239, 'input_token_details': {'cache_read': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import os\n",
    "\n",
    "# Set the API key\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyA2WApH-qFk1hetH3wmpT1pR6J0OOm3U3c\"\n",
    "\n",
    "# Use the correct model name from the list\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro-latest\")\n",
    "\n",
    "# Test the model with a prompt\n",
    "response = llm.invoke(\"Generate a marketing slogan for AI-powered advertising.\")\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
